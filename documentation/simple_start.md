# Simple Start

## Introduction

This is the simplest path for recreating an MPC deployment using the automated framework prepared by the team over the past semester. Other documents contain additional notes taken during the process of testing and developing our automation and may be useful for extending the existing framework or for understanding the steps that were taken to reach this 

## High-Level Steps

1. Create three nodes with Ubuntu 20.04 installed on OpenStack or CloudLab.
2. Clone the project repo from github to your local computer.
3. Modify ansible environment files for your nodes and your login information.
4. Run ansible playbook or ad-hoc commands.
5. If running the playbook, examine the returned data.

## More Detailed Steps

*Please read through these steps completely before starting to make sure you understand the entire flow.*

1. The simplest (non-local) platforms to consider testing are the MOC OpenStack which offers VMs or Bare-Metal nodes from CloudLab. We suggest selecting one of these two in order to most easily follow these instructions. Local deployment, using Docker, or using OpenShift remain options but either do not make use of our automation or have additional challenges. Consequently, we do not describe them here.
1. Having selected either the MOC OpenStack or CloudLab, make sure that you are able to login to the respective web portals and that you have followed their instructions such that you have a local SSH key with which you will be able to access any nodes. [MOC OpenStack video and text tutorials](https://docs.massopen.cloud/en/latest/how-tos/Getting-started.html) [CloudLab tutorial: signup, joining a project, SSH setup](https://docs.cloudlab.us/)
1. At this point we assume you have an SSH key for the desired platform at your disposal. It is now time to create three nodes on either OpenStack or CloudLab.
    1. In the case of MOC OpenStack we suggest following the steps for [launching a VM](https://docs.massopen.cloud/en/latest/openstack/Launch-a-VM.html) and selecting Ubuntu 20.04 LTS as a distribution. You can either do this manually three times or select the menu option to create three instances of the same VM. [Follow the suggestions](https://docs.massopen.cloud/en/latest/openstack/Assign-a-Floating-IP.html) for configuring one of the VMs you created such that it has a floating IP. We will be using this node as the primary node both for accessing the others and for launching any MPI commands. For additional references, feel free to flip through the nodes related to OpenStack. See the README "Links to other Documentation" section to find OpenStack notes.
    1. In the case of CloudLab you can create an custom experiment starting from one of the Geni-Lib scripts located under `baremetal`. We suggest a simple, single-cluster LAN topology to start which you can create by copying the contents of `baremetal/lan_cl.py` into the CloudLab portal. Make sure to review the OS being specified and modify it to indicate `urn:publicid:IDN+emulab.net+image+emulab-ops:UBUNTU20-64-STD` for Ubuntu 20.04 if it doesn't already. Refer to [these notes](https://docs.cloudlab.us/creating-profiles.html) for profile creation. Once the profile is created, launch an instance of the experiment. We have had good success with m510 or m400 node on the Utah cluster. See ["Getting Started"](https://docs.cloudlab.us/getting-started.html) to anticipate the options when launching an experiment.
1. Now, at this point there should be three Ubuntu 20.04 nodes configured on a virtual LAN on either the MOC OpenStack or CloudLab. Feel free to try using SSH to connect to each of the nodes in turn. on CloudLab this should be simple as each node will have an external IP address. On the MOC, the node with the floating IP address can be accessed directly, the others will require that you load your SSH key locally and use Agent Forwarding. See `documentation/openstack/ssh_noted.md` for details.
1. Now, if all of the nodes are accessible, we can move to making the necessary configuration changes to our ansible environment. Looking inside `ansible/environment/` you will see caad and cloudlab directories. These contain the previously working environments used by the team which can be useful as reference. We suggest copying the reference directory instead which has an example configuration. Having created a copy of reference also located under `ansible/environments/` you will be opening and editing `ansible/environments/<reference_copy>/group_vars/all.yaml` as well as each of the `ansible/environments/<reference_copy>/host_vars/node-<#>.yaml` files. In all.yaml, replace `<Specify_username>` with your MOC system username and `<Specify_SSH_key_file>` with the path to your MOC SSH private key. In each of the `node-<#>.yaml` files replace `<Specify_IP_or_FQDN>` with the IP address or fully qualified domain name (FQDN) of each node. For MOC OpenStack this will be the floating IP for node-0 and two internal IP addresses for the other nodes. For CloudLab this will be an FQDN specific to the cluster being used.
    1. Note: If CloudLab is being used, the behavior of proxying SSH connections through the primary node is not needed. As a result in `ansible/environments/<reference_copy>/hosts` the bastion and intranet groups can be commented out or deleted. `ansible/environments/<reference_copy>/group_vars/intranet.yaml` can be deleted or left but is unneeded either way.
1. With all of this setup complete, make sure that your terminal is open to `ansible/` and then load your OpenStack or CloudLab key to an ssh-agent (`scripts_other/add_<NAME>_key_to_agent.sh` can be modified to dod this in a single step and then called with the `source` command). (Note: additionally in a WSL environment at least, it was necessary to use ``export ANSIBLE_CONFIG=`pwd`` when located in the `ansible/` directory. If you skip this and see a warning when running ansible commands, return and run this command).
1. With an SSH key loaded, we can now test that ansible is working. We can make an ad-hoc ansible command (not in a playbook) to verify our environment. For example: `ansible -i environment/<reference_copy>/hosts -m shell -a hostname` should successfully print the hostname of each of the nodes we configured if our setup went well. If not, review the previous steps for a possible missed step.
1. If the ad-hoc command worked successfully, we can now run a playbook as follows. Note: this playbook was designed to prepare all of the dependencies needed on an Ubuntu 20.04 system, if another OS was used, please create additional `*_os_<OPERATING_SYSTEM>.yaml` files under `ansible/` to specify the equivalent package names needed. The command to run the playbook is as follows: `ansible-playbook -K -i environment/<reference_copy>/hosts ansible_test.yaml` when prompted with the `BECOME:` prompt, enter the sudo password or in the case of CloudLab just hit enter. (It should be possible to either create ansible secrets to avoid this step or to install a module on the OS that allows for password-less sudo when logging in via SSH but we have chosen not to add that step here).
1. Now, the playbook should be running and you can follow along with the text in `ansible_test.yaml` eventually all the nodes should have their dependencies installed, local source files should be copied over, a build of exp-exchange should occur, and eventually, the primary node should start the experiment. Upon completion, the primary node should copy the output *.csv file to `../retrieved/` where it can be examined.
1. If this has worked successfully, there are several other options for next steps:
    1. Consider adding `scorep` to the experiment Makefile under `experiments/` and rerunning the playbook to capture benchmarking data. This can be retrieved by modifying which files the playbook copies back or by using scp or rsync to retrieve it from the primary node. Then it can be examined with a tool such as the CUBE GUI
    1. Consider trying out CloudLab if you have already tested OpenShift or vice-versa. Optionally, other topologies can be tested on CloudLab by employing different scripts located under `baremetal/`.
    1. Read through the other notes in the documentation directories to gain additional insight into other features that were not covered in this introduction.
    1. For any questions or feedback, feel free to reach out to the team using the emails located in README.md
1. Thanks for the interest and trying out this guide!